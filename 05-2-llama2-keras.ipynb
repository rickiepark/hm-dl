{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb145d9f-dc9d-4804-870f-b4866db0244e",
   "metadata": {
    "id": "cb145d9f-dc9d-4804-870f-b4866db0244e"
   },
   "source": [
    "# 05-2 LLaMA-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f3b4d4-5717-4b1c-a8a9-c4c98056667c",
   "metadata": {
    "id": "30f3b4d4-5717-4b1c-a8a9-c4c98056667c"
   },
   "source": [
    "<table align=\"left\"><tr><td>\n",
    "<a href=\"https://colab.research.google.com/github/rickiepark/hm-dl/blob/main/05-2-llama2-keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"코랩에서 실행하기\"/></a>\n",
    "</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yCXoZXSjKXXb",
   "metadata": {
    "id": "yCXoZXSjKXXb"
   },
   "source": [
    "코랩에서 이 노트북을 실행하려면 High-RAM CPU 런타임을 사용해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcda3e5-1778-4b38-8ab0-d7f10b84c161",
   "metadata": {
    "id": "abcda3e5-1778-4b38-8ab0-d7f10b84c161",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 케라스에서 LLaMA-2 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aec675-a9ed-4037-ab17-1f3b160951ee",
   "metadata": {
    "id": "c7aec675-a9ed-4037-ab17-1f3b160951ee",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "** 라마-2, 라마-3 모델을 사용하려면 먼저 메타에 사용 허가를 얻어야 합니다. 자세한 내용은 도서를 참고하세요.**\n",
    "\n",
    "캐글에서 라마-2 모델을 다운로드하려면 캐글 API 토큰을 생성하여 ~/.kaggle/ 디렉토리에 저장하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "v5yhVjan3OSy",
   "metadata": {
    "id": "v5yhVjan3OSy"
   },
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle/\n",
    "!mv kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5WjQpch7wlp6",
   "metadata": {
    "id": "5WjQpch7wlp6"
   },
   "source": [
    "이 절의 코드를 실행하려면 `keras-nlp` 패키지를 설치해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "HI9Tu-ZjukRO",
   "metadata": {
    "id": "HI9Tu-ZjukRO"
   },
   "outputs": [],
   "source": [
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f3946f0-771b-4555-9666-c3eb97899d10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "gather": {
     "logged": 1715949100830
    },
    "id": "8f3946f0-771b-4555-9666-c3eb97899d10",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputId": "69f2d951-2c11-434f-9351-6e1751fd5f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/keras/llama2/keras/llama2_7b_en/1/download/config.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 604/604 [00:00<00:00, 528kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/keras/llama2/keras/llama2_7b_en/1/download/model.weights.h5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12.6G/12.6G [01:37<00:00, 138MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/keras/llama2/keras/llama2_7b_en/1/download/tokenizer.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 397/397 [00:00<00:00, 778kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/models/keras/llama2/keras/llama2_7b_en/1/download/assets/tokenizer/vocabulary.spm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 488k/488k [00:00<00:00, 82.8MB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"llama_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"llama_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ llama_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LlamaTokenizer</span>)                              │                       Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">32,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ llama_tokenizer (\u001b[38;5;33mLlamaTokenizer\u001b[0m)                              │                       Vocab size: \u001b[38;5;34m32,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"llama_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"llama_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ llama_backbone_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">6,738,415,616</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LlamaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32000</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144,000</span> │ llama_backbone_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ llama_backbone_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)        │   \u001b[38;5;34m6,738,415,616\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mLlamaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32000\u001b[0m)       │     \u001b[38;5;34m262,144,000\u001b[0m │ llama_backbone_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,738,415,616</span> (25.10 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,738,415,616\u001b[0m (25.10 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,738,415,616</span> (25.10 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,738,415,616\u001b[0m (25.10 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llama2 = keras_nlp.models.LlamaCausalLM.from_preset('llama2_7b_en')\n",
    "llama2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "336dd0da-f802-4b54-872d-5373cbb53057",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "gather": {
     "logged": 1715949144430
    },
    "id": "336dd0da-f802-4b54-872d-5373cbb53057",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputId": "03659740-6269-4432-c4ef-bd25de9c2498"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'stay hungry, stay foolish by Steve Jobs'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler = keras_nlp.samplers.TopPSampler(p=0.8, seed=42)\n",
    "llama2.compile(sampler=sampler)\n",
    "llama2.generate('stay hungry, stay', max_length=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ab4424-48bc-4224-b47b-cae04dfcc9b5",
   "metadata": {
    "id": "d5ab4424-48bc-4224-b47b-cae04dfcc9b5",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 센텐스피스 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "274d4503-6cee-4c55-b2bd-f23ff1174e7f",
   "metadata": {
    "gather": {
     "logged": 1716021821536
    },
    "id": "274d4503-6cee-4c55-b2bd-f23ff1174e7f",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "llama_tokenizer = keras_nlp.models.LlamaTokenizer.from_preset('llama2_7b_en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac33303b-e97c-4752-b33f-b6303e0c1068",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1716024433859
    },
    "id": "ac33303b-e97c-4752-b33f-b6303e0c1068",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputId": "ad98b287-ebbf-439e-b140-d5f8e920c898"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 7952,  9074, 14793, 29892,  7952], dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = llama_tokenizer.tokenize('stay hungry, stay')\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7cc85bf-c891-4476-af07-f35e5c70b913",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1716024434912
    },
    "id": "d7cc85bf-c891-4476-af07-f35e5c70b913",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputId": "0b6859b6-8b4c-4799-d51f-104711e0cf86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁stay ▁hun gry , ▁stay "
     ]
    }
   ],
   "source": [
    "for ids in token_ids:\n",
    "    print(llama_tokenizer.id_to_token(ids), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f62e611b-1f3c-4bfc-a229-1a6de70eb2ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gather": {
     "logged": 1716024450832
    },
    "id": "f62e611b-1f3c-4bfc-a229-1a6de70eb2ef",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputId": "46c445fd-9d72-428f-eb53-1a55ceefd090"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([15043, 22172], dtype=int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_tokenizer.tokenize('Hello hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f52d6da1-0d60-4e4e-8c02-2569ca83659e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "gather": {
     "logged": 1716023964899
    },
    "id": "f52d6da1-0d60-4e4e-8c02-2569ca83659e",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputId": "17291f61-6324-4942-fd03-c9b20f42495d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'stay hungry, stay'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_tokenizer.detokenize(token_ids)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernel_info": {
   "name": "py310_tf216_keras3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
