{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 03-2 트랜스포머를 사용한 텍스트 생성"
      ],
      "metadata": {
        "id": "cb145d9f-dc9d-4804-870f-b4866db0244e"
      },
      "id": "cb145d9f-dc9d-4804-870f-b4866db0244e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table align=\"left\"><tr><td>\n",
        "<a href=\"https://colab.research.google.com/github/rickiepark/hm-dl/blob/main/03-2-llama2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"코랩에서 실행하기\"/></a>\n",
        "</td></tr></table>"
      ],
      "metadata": {
        "id": "30f3b4d4-5717-4b1c-a8a9-c4c98056667c"
      },
      "id": "30f3b4d4-5717-4b1c-a8a9-c4c98056667c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "코랩에서 이 노트북을 실행하려면 High-RAM CPU 런타임을 사용해야 합니다."
      ],
      "metadata": {
        "id": "yCXoZXSjKXXb"
      },
      "id": "yCXoZXSjKXXb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 절의 코드를 실행하려면 `keras-nlp` 패키지와 허깅페이스 `transformers` 패키지를 위한 `tf-keras`를 설치해야 합니다."
      ],
      "metadata": {
        "id": "5WjQpch7wlp6"
      },
      "id": "5WjQpch7wlp6"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U tensorflow keras-nlp tf-keras"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-nlp\n",
            "  Downloading keras_nlp-0.12.1-py3-none-any.whl (570 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.5/570.5 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tf-keras in /usr/local/lib/python3.10/dist-packages (2.15.1)\n",
            "Collecting tf-keras\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Collecting h5py>=3.10.0 (from tensorflow)\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.0)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras>=3.0.0 (from tensorflow)\n",
            "  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Collecting keras-core (from keras-nlp)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (2023.12.25)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (13.7.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (0.1.8)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (0.2.5)\n",
            "Collecting tensorflow-text (from keras-nlp)\n",
            "  Downloading tensorflow_text-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Collecting namex (from keras>=3.0.0->tensorflow)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Collecting optree (from keras>=3.0.0->tensorflow)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-nlp) (4.66.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nlp) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
            "Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras-core, keras, tensorflow, tf-keras, tensorflow-text, keras-nlp\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.15.1\n",
            "    Uninstalling tf_keras-2.15.1:\n",
            "      Successfully uninstalled tf_keras-2.15.1\n",
            "Successfully installed h5py-3.11.0 keras-3.3.3 keras-core-0.1.7 keras-nlp-0.12.1 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.1 tensorflow-text-2.16.1 tf-keras-2.16.0\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "editable": false,
        "run_control": {
          "frozen": true
        },
        "id": "daefa5d0-4eb4-4507-a047-203d54027b6d",
        "outputId": "c141743a-c7cf-46a7-9f79-72167d4295e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "daefa5d0-4eb4-4507-a047-203d54027b6d"
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras_nlp\n",
        "\n",
        "keras.__version__, keras_nlp.__version__"
      ],
      "metadata": {
        "id": "Nr6x5S7E0vWQ",
        "outputId": "128e0648-bd7a-4c0f-f579-accbf68f6f0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Nr6x5S7E0vWQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('3.3.3', '0.12.1')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import keras_nlp"
      ],
      "metadata": {
        "id": "ms4sk9cCvXif"
      },
      "id": "ms4sk9cCvXif",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_causal_mask(seq_len):\n",
        "    n_hori = keras.ops.arange(seq_len)\n",
        "    n_vert = keras.ops.expand_dims(n_hori, axis=-1)\n",
        "    mask = n_vert >= n_hori\n",
        "    return mask"
      ],
      "metadata": {
        "id": "yz5GK1H8vVdu"
      },
      "id": "yz5GK1H8vVdu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_attention_mask(padding_mask):\n",
        "    # padding_mask 크기가 (2, 5)라고 가정해 보죠.\n",
        "    batch_size, seq_len = keras.ops.shape(padding_mask)\n",
        "    # causal_mask 크기는 (5, 5)가 됩니다.\n",
        "    causal_mask = make_causal_mask(seq_len)\n",
        "    # 배치 차원을 추가해 (2, 5, 5)로 만듭니다.\n",
        "    causal_mask = keras.ops.broadcast_to(causal_mask, (batch_size, seq_len, seq_len))\n",
        "    # 브로드캐스팅을 위해 padding_mask 크기를 (2, 1, 5)로 만듭니다.\n",
        "    padding_mask = keras.ops.expand_dims(padding_mask, axis=1)\n",
        "    return keras.ops.minimum(causal_mask, padding_mask)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716516636255
        },
        "id": "5c08ad1d-1721-4912-828e-c35226ee8b93"
      },
      "id": "5c08ad1d-1721-4912-828e-c35226ee8b93"
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionMask(keras.Layer):\n",
        "    def call(self, padding_mask):\n",
        "        return make_attention_mask(padding_mask)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716516669415
        },
        "id": "b2fba626-172b-4eee-9a41-ce49a9bfc2e3"
      },
      "id": "b2fba626-172b-4eee-9a41-ce49a9bfc2e3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLaMa-2"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "26ea8bf5-adbc-4956-b264-6ef1cd98d4df"
      },
      "id": "26ea8bf5-adbc-4956-b264-6ef1cd98d4df"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 로터리 위치 임베딩"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "11cd9a2e-0a31-484b-8728-5f64a03310bf"
      },
      "id": "11cd9a2e-0a31-484b-8728-5f64a03310bf"
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰 임베딩 크기\n",
        "embed_dim = 4096\n",
        "\n",
        "def rotary_position_embedding(inputs, token_pos):\n",
        "    # theta 각도를 생성합니다.\n",
        "    freqs = keras.ops.arange(0, embed_dim, 2, dtype='float32') / embed_dim\n",
        "    inverse_freqs = 1 / (10000**freqs)\n",
        "    # m * theta\n",
        "    embedding = token_pos * inverse_freqs\n",
        "    cos_emb = keras.ops.cos(embedding)\n",
        "    sin_emb = keras.ops.sin(embedding)\n",
        "    # 입력을 절반으로 나눕니다.\n",
        "    x1, x2 = keras.ops.split(inputs, 2)\n",
        "    # 회전 변환을 적용합니다.\n",
        "    new_x1 = x1 * cos_emb - x2 * sin_emb\n",
        "    new_x2 = x1 * sin_emb + x2 * cos_emb\n",
        "    return keras.ops.concatenate((new_x1, new_x2))\n",
        "\n",
        "# 가상의 토큰 임베딩\n",
        "inputs = keras.ops.ones(embed_dim)\n",
        "# 두 번째 위치에 있는 토큰에 로터리 위치 임베딩을 적용합니다.\n",
        "rotary_position_embedding(inputs, 1)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4096,), dtype=float32, numpy=\n",
              "array([-0.30116874, -0.2949654 , -0.28878427, ...,  1.0001013 ,\n",
              "        1.0001009 ,  1.0001005 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715755618883
        },
        "id": "1ba76d72-0f86-4ebe-982c-0ed2cbc17ea1",
        "outputId": "3500fb7d-795b-4812-adf2-364fc06cc880",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1ba76d72-0f86-4ebe-982c-0ed2cbc17ea1"
    },
    {
      "cell_type": "code",
      "source": [
        "rotary_embedding = keras_nlp.layers.RotaryEmbedding()\n",
        "rotary_embedding(keras.ops.ones((1, 2, embed_dim)))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2, 4096), dtype=float32, numpy=\n",
              "array([[[ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
              "          1.        ,  1.        ],\n",
              "        [-0.30116874, -0.2949654 , -0.28878427, ...,  1.0001013 ,\n",
              "          1.0001009 ,  1.0001005 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715755427060
        },
        "id": "979a38aa-320c-468f-956d-104419cfbaf1",
        "outputId": "2b555aa9-1661-4e52-94ab-ca1a7ac943ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "979a38aa-320c-468f-956d-104419cfbaf1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RMS 정규화"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "345951c7-d3d8-4786-97f7-0f1b4f8dc29a"
      },
      "id": "345951c7-d3d8-4786-97f7-0f1b4f8dc29a"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def rms_norm(x):\n",
        "    scale = 1.0     # 실제로는 훈련되는 가중치입니다.\n",
        "    epsilon = 1e-6\n",
        "    var = keras.ops.mean(keras.ops.power(x, 2), axis=-1, keepdims=True)\n",
        "    return scale * x / keras.ops.sqrt(var + epsilon)\n",
        "\n",
        "x = np.array([1, 2, 3])\n",
        "rms_norm(x)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.46291, 0.92582, 1.38873], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715836293471
        },
        "id": "b444fd37-2f4a-4219-8829-211cc6d0f39c",
        "outputId": "6c903283-8bc2-41a8-d135-ee2f85d052cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "b444fd37-2f4a-4219-8829-211cc6d0f39c"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_nlp.src.models.llama.llama_layernorm import LlamaLayerNorm\n",
        "\n",
        "llama_norm = LlamaLayerNorm()\n",
        "llama_norm(x)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.46291, 0.92582, 1.38873], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716342391846
        },
        "id": "ad6c705c-8078-4721-b932-54fbcb7d5bcd",
        "outputId": "71ce89ac-1c73-4687-9d63-edc10597eda0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ad6c705c-8078-4721-b932-54fbcb7d5bcd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SwiGLU 활성화 함수"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "9be5c637-137e-4655-a710-a72dc4dc93cd"
      },
      "id": "9be5c637-137e-4655-a710-a72dc4dc93cd"
    },
    {
      "cell_type": "code",
      "source": [
        "# 피드 포워드 네트워크의 입력 크기가 (10, 4096)이고,\n",
        "# 유닛 개수는 11,008개, 임베딩 차원은 4,096이라고 가정합니다.\n",
        "x = keras.ops.ones((10, 4096))\n",
        "x1 = layers.Dense(11008, activation='silu', use_bias=False)(x)\n",
        "x2 = layers.Dense(11008, use_bias=False)(x)\n",
        "x = x1 * x2\n",
        "x = layers.Dense(4096, use_bias=False)(x)\n",
        "x"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 4096), dtype=float32, numpy=\n",
              "array([[-0.6577311 , -0.4733592 ,  0.26339507, ...,  0.08605745,\n",
              "        -0.01683542, -0.24151087],\n",
              "       [-0.6577311 , -0.4733592 ,  0.26339507, ...,  0.08605745,\n",
              "        -0.01683542, -0.24151087],\n",
              "       [-0.6577311 , -0.4733592 ,  0.26339507, ...,  0.08605745,\n",
              "        -0.01683542, -0.24151087],\n",
              "       ...,\n",
              "       [-0.6577311 , -0.4733592 ,  0.26339507, ...,  0.08605745,\n",
              "        -0.01683542, -0.24151087],\n",
              "       [-0.6577311 , -0.4733592 ,  0.26339507, ...,  0.08605745,\n",
              "        -0.01683542, -0.24151087],\n",
              "       [-0.6577311 , -0.4733592 ,  0.26339507, ...,  0.08605745,\n",
              "        -0.01683542, -0.24151087]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716349085852
        },
        "id": "1e4ba2bb-7d42-4f10-8ec9-872be923b3d6",
        "outputId": "48d7b9e5-e4c2-4d7a-dc8b-8f07753fd909",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1e4ba2bb-7d42-4f10-8ec9-872be923b3d6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 라마 2 구현하기"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "41196c13-9631-4e74-9fdb-5dd2e5ced358"
      },
      "id": "41196c13-9631-4e74-9fdb-5dd2e5ced358"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_nlp.src.models.llama.llama_attention import LlamaAttention\n",
        "\n",
        "def llama_decoder(x, padding_mask, num_query_heads, num_key_value_heads,\n",
        "                  interm_dim, hidden_dim):\n",
        "    # 어텐션 마스크를 계산합니다.\n",
        "    attention_mask = AttentionMask()(padding_mask)\n",
        "    # 스킵 연결을 준비합니다.\n",
        "    residual = x\n",
        "    x = LlamaLayerNorm()(x)\n",
        "    # 멀티 헤드 어텐션을 통과합니다.\n",
        "    llama_attention = LlamaAttention(num_query_heads=num_query_heads,\n",
        "                                     num_key_value_heads=num_key_value_heads,\n",
        "                                     dropout=0.0)\n",
        "    x = llama_attention(x, attention_mask)\n",
        "    # 스킵 연결\n",
        "    x = x + residual\n",
        "    # 스킵 연결을 준비합니다.\n",
        "    residual = x\n",
        "    # 피드 포워드 네트워크\n",
        "    x = LlamaLayerNorm()(x)\n",
        "    x1 = layers.Dense(interm_dim, activation='silu', use_bias=False)(x)\n",
        "    x2 = layers.Dense(interm_dim, use_bias=False)(x)\n",
        "    x = x1 * x2\n",
        "    x = layers.Dense(hidden_dim, use_bias=False)(x)\n",
        "    # 스킵 연결\n",
        "    x = x + residual\n",
        "    return x"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716341964106
        },
        "id": "8c30d559-78cc-40b9-8f75-e73f40455a41"
      },
      "id": "8c30d559-78cc-40b9-8f75-e73f40455a41"
    },
    {
      "cell_type": "code",
      "source": [
        "# LLaMa 2\n",
        "vocab_size = 32000\n",
        "num_layers = 32\n",
        "num_query_heads = 32\n",
        "num_key_value_heads = 32\n",
        "interm_dim = 11008\n",
        "hidden_dim = 4096\n",
        "\n",
        "token_ids = keras.Input(shape=(None,))\n",
        "padding_mask = keras.Input(shape=(None,))\n",
        "\n",
        "token_embedding_layer = keras_nlp.layers.ReversibleEmbedding(vocab_size, hidden_dim,\n",
        "                                                             tie_weights=False)\n",
        "x = token_embedding_layer(token_ids)\n",
        "\n",
        "for _ in range(num_layers):\n",
        "    x = llama_decoder(x, padding_mask, num_query_heads, num_key_value_heads,\n",
        "                      interm_dim, hidden_dim)\n",
        "\n",
        "x = LlamaLayerNorm()(x)\n",
        "outputs = token_embedding_layer(x, reverse=True)\n",
        "model = keras.Model(inputs=(token_ids, padding_mask),\n",
        "                    outputs=(outputs))\n",
        "model.summary(line_length=100)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715939659843
        },
        "id": "91c01f16-9292-4e3e-b748-0e7aacafccf3"
      },
      "id": "91c01f16-9292-4e3e-b748-0e7aacafccf3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 케라스에서 LLaMa-2 사용하기"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "abcda3e5-1778-4b38-8ab0-d7f10b84c161"
      },
      "id": "abcda3e5-1778-4b38-8ab0-d7f10b84c161"
    },
    {
      "cell_type": "markdown",
      "source": [
        "** 라마-2, 라마-3 모델을 사용하려면 먼저 메타에 사용 허가를 얻어야 합니다. 자세한 내용은 도서를 참고하세요.**\n",
        "\n",
        "캐글에서 라마-2 모델을 다운로드하려면 캐글 API 토큰을 생성하여 ~/.kaggle/ 디렉토리에 저장하세요."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "c7aec675-a9ed-4037-ab17-1f3b160951ee"
      },
      "id": "c7aec675-a9ed-4037-ab17-1f3b160951ee"
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle/\n",
        "!mv kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "v5yhVjan3OSy"
      },
      "id": "v5yhVjan3OSy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llama2 = keras_nlp.models.LlamaCausalLM.from_preset('llama2_7b_en', dtype='float16')\n",
        "llama2.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/llama2/keras/llama2_7b_en/1/download/metadata.json...\n",
            "100%|██████████| 142/142 [00:00<00:00, 131kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/llama2/keras/llama2_7b_en/1/download/task.json...\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/llama2/keras/llama2_7b_en/1/download/config.json...\n",
            "100%|██████████| 604/604 [00:00<00:00, 551kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/llama2/keras/llama2_7b_en/1/download/model.weights.h5...\n",
            "100%|██████████| 12.6G/12.6G [11:44<00:00, 19.1MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/llama2/keras/llama2_7b_en/1/download/preprocessor.json...\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/llama2/keras/llama2_7b_en/1/download/tokenizer.json...\n",
            "100%|██████████| 397/397 [00:00<00:00, 884kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/llama2/keras/llama2_7b_en/1/download/assets/tokenizer/vocabulary.spm...\n",
            "100%|██████████| 488k/488k [00:00<00:00, 573kB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mPreprocessor: \"llama_causal_lm_preprocessor\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"llama_causal_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ llama_tokenizer (\u001b[38;5;33mLlamaTokenizer\u001b[0m)                   │                                              \u001b[38;5;34m32,000\u001b[0m │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ llama_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LlamaTokenizer</span>)                   │                                              <span style=\"color: #00af00; text-decoration-color: #00af00\">32,000</span> │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"llama_causal_lm\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"llama_causal_lm\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ llama_backbone_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)        │   \u001b[38;5;34m6,738,415,616\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mLlamaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32000\u001b[0m)       │     \u001b[38;5;34m262,144,000\u001b[0m │ llama_backbone_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ llama_backbone_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">6,738,415,616</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LlamaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32000</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144,000</span> │ llama_backbone_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,738,415,616\u001b[0m (25.10 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,738,415,616</span> (25.10 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,738,415,616\u001b[0m (25.10 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,738,415,616</span> (25.10 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715949100830
        },
        "id": "8f3946f0-771b-4555-9666-c3eb97899d10",
        "outputId": "d211f00c-1911-49ab-828e-9ceeaace0c60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        }
      },
      "id": "8f3946f0-771b-4555-9666-c3eb97899d10"
    },
    {
      "cell_type": "code",
      "source": [
        "llama2.generate('stay hungry, stay', max_length=20)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stay hungry, stay humble\\nI’ve been a little busy lately so I'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715949144430
        },
        "id": "336dd0da-f802-4b54-872d-5373cbb53057",
        "outputId": "9a71734b-dbcf-4b1e-8204-f5072712440b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "id": "336dd0da-f802-4b54-872d-5373cbb53057"
    },
    {
      "cell_type": "code",
      "source": [
        "del llama2"
      ],
      "metadata": {
        "id": "fXSfZjdYGMbM"
      },
      "id": "fXSfZjdYGMbM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 센텐스피스 토크나이저"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "d5ab4424-48bc-4224-b47b-cae04dfcc9b5"
      },
      "id": "d5ab4424-48bc-4224-b47b-cae04dfcc9b5"
    },
    {
      "cell_type": "code",
      "source": [
        "llama_tokenizer = keras_nlp.models.LlamaTokenizer.from_preset('llama2_7b_en')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716021821536
        },
        "id": "274d4503-6cee-4c55-b2bd-f23ff1174e7f"
      },
      "id": "274d4503-6cee-4c55-b2bd-f23ff1174e7f"
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = llama_tokenizer.tokenize('stay hungry, stay')\n",
        "token_ids"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 7952,  9074, 14793, 29892,  7952], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716024433859
        },
        "id": "ac33303b-e97c-4752-b33f-b6303e0c1068",
        "outputId": "55b68f42-1872-40d7-83ca-98b97d8ef430",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ac33303b-e97c-4752-b33f-b6303e0c1068"
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in token_ids:\n",
        "    print(llama_tokenizer.id_to_token(ids), end=' ')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁stay ▁hun gry , ▁stay "
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716024434912
        },
        "id": "d7cc85bf-c891-4476-af07-f35e5c70b913",
        "outputId": "17f6c6eb-10b0-4998-eacc-c0ed711b3cca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "d7cc85bf-c891-4476-af07-f35e5c70b913"
    },
    {
      "cell_type": "code",
      "source": [
        "llama_tokenizer.tokenize('Hello hello')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([15043, 22172], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716024450832
        },
        "id": "f62e611b-1f3c-4bfc-a229-1a6de70eb2ef",
        "outputId": "7cd5358b-49a1-41a3-a152-b2d6ddfd99a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "f62e611b-1f3c-4bfc-a229-1a6de70eb2ef"
    },
    {
      "cell_type": "code",
      "source": [
        "llama_tokenizer.detokenize(token_ids)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'stay hungry, stay'>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716023964899
        },
        "id": "f52d6da1-0d60-4e4e-8c02-2569ca83659e",
        "outputId": "49e6d56c-f14d-4297-91b3-73cd13618b53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "f52d6da1-0d60-4e4e-8c02-2569ca83659e"
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "py310_tf216_keras3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}