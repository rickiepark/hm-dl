{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "eaa836a9-0e17-42e4-b2ba-83d098258aee",
      "metadata": {
        "id": "eaa836a9-0e17-42e4-b2ba-83d098258aee"
      },
      "source": [
        "# 02-3 강아지와 고양이 사진 분류 모델의 성능 개선하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93ea5880-c286-4b51-9880-4f0839f8aa8f",
      "metadata": {
        "id": "93ea5880-c286-4b51-9880-4f0839f8aa8f"
      },
      "source": [
        "<table align=\"left\"><tr><td>\n",
        "<a href=\"https://colab.research.google.com/github/rickiepark/hm-dl/blob/main/02-3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"코랩에서 실행하기\"/></a>\n",
        "</td></tr></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fa9d423-b290-47ef-91b8-54d70114c24a",
      "metadata": {
        "id": "2fa9d423-b290-47ef-91b8-54d70114c24a"
      },
      "source": [
        "## ResNet 모델 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 배치 정규화"
      ],
      "metadata": {
        "id": "ZnFKCWp2f4au"
      },
      "id": "ZnFKCWp2f4au"
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(224, 224, 3))\n",
        "x = layers.ZeroPadding2D(padding=3)(inputs)\n",
        "x = layers.Conv2D(64, 7, strides=2)(x)\n",
        "x = layers.BatchNormalization(epsilon=1e-5)(x)\n",
        "x = layers.Activation('relu')(x)"
      ],
      "metadata": {
        "id": "LJcv_KcB0X3w"
      },
      "id": "LJcv_KcB0X3w",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "77745c7f-746a-4bb5-be0d-6485eed7e8c0",
      "metadata": {
        "id": "77745c7f-746a-4bb5-be0d-6485eed7e8c0"
      },
      "outputs": [],
      "source": [
        "x = layers.ZeroPadding2D(padding=1)(x)\n",
        "x = layers.MaxPooling2D(3, strides=2)(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a55e3e7-f259-443c-98af-b5af2b0023bf",
      "metadata": {
        "id": "6a55e3e7-f259-443c-98af-b5af2b0023bf"
      },
      "source": [
        "### 잔차 스택 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fb7bfafe-36ef-482d-bc85-afdee3a72459",
      "metadata": {
        "id": "fb7bfafe-36ef-482d-bc85-afdee3a72459"
      },
      "outputs": [],
      "source": [
        "def build_stack(x):\n",
        "    # 첫 번째 잔차 스택의 첫 번째 잔차 블록만 스트라이드 1을 사용합니다\n",
        "    x = residual_stack(x, 3, 64, first_stride=1)\n",
        "    # 두 번째~네 번째 잔차 블록을 만듭니다\n",
        "    for blocks, filters in [(4, 128), (6, 256), (3, 512)]:\n",
        "        x = residual_stack(x, blocks, filters, first_stride=2)\n",
        "    return x\n",
        "\n",
        "def residual_stack(x, blocks, filters, first_stride=2):\n",
        "    # 첫 번째 잔차 블록은 합성곱 스킵 연결을 사용하고\n",
        "    # 이 잔차 블록의 첫 번째 합성곱 스트라이드는 first_stride입니다.\n",
        "    x = residual_block(x, filters, first_stride=first_stride, conv_skip=True)\n",
        "    for _ in range(1, blocks):\n",
        "        # 나머지 잔차 블록의 첫 번째 합성곱 스트라이드는 1입니다.\n",
        "        x = residual_block(x, filters, first_stride=1, conv_skip=False)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "73f994f7-9a14-4932-b6e8-f1268cc9a928",
      "metadata": {
        "id": "73f994f7-9a14-4932-b6e8-f1268cc9a928"
      },
      "outputs": [],
      "source": [
        "def residual_block(x, filters, first_stride=1, conv_skip=False):\n",
        "    skip_conn = x\n",
        "    # 합성곱과 배치 정규화, 렐루 활성화 함수를 반복합니다\n",
        "    # 1x1, filters개 필터, 스트라이드는 first_stride에 따라 1 또는 2\n",
        "    x = layers.Conv2D(filters=filters, kernel_size=1,\n",
        "                      strides=first_stride)(x)\n",
        "    x = layers.BatchNormalization(epsilon=1e-5)(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    # 3x3, filters개 필터\n",
        "    x = layers.Conv2D(filters=filters, kernel_size=3,\n",
        "                      padding='same')(x)\n",
        "    x = layers.BatchNormalization(epsilon=1e-5)(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    # 1x1, filters*4개 필터\n",
        "    x = layers.Conv2D(filters=filters*4, kernel_size=1)(x)\n",
        "    x = layers.BatchNormalization(epsilon=1e-5)(x)\n",
        "    # conv_skip이 True이면 1x1 합성곱을 사용해 채널 크기를 filters*4로 늘립니다\n",
        "    if conv_skip == True:\n",
        "        skip_conn = layers.Conv2D(filters=filters*4, kernel_size=1,\n",
        "                                  strides=first_stride)(skip_conn)\n",
        "        skip_conn = layers.BatchNormalization(epsilon=1e-5)(skip_conn)\n",
        "    x = layers.Add()([skip_conn, x])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet 모델 만들기"
      ],
      "metadata": {
        "id": "87Mbj-BY3PXz"
      },
      "id": "87Mbj-BY3PXz"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "037bc9db-06ef-43b6-8ded-279539d22865",
      "metadata": {
        "id": "037bc9db-06ef-43b6-8ded-279539d22865"
      },
      "outputs": [],
      "source": [
        "x = build_stack(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "outputs = layers.Dense(1000, activation='softmax')(x)"
      ],
      "metadata": {
        "id": "n9-u6piLitxj"
      },
      "id": "n9-u6piLitxj",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "5xEBR4yyiv4A"
      },
      "id": "5xEBR4yyiv4A",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cf557793-1422-4a55-a058-fa9e69660861",
      "metadata": {
        "id": "cf557793-1422-4a55-a058-fa9e69660861"
      },
      "outputs": [],
      "source": [
        "def build_stack101(x):\n",
        "    # 첫 번째 잔차 스택의 첫 번째 잔차 블록만 스트라이드 1을 사용합니다\n",
        "    x = residual_stack(x, 3, 64, first_stride=1)\n",
        "    # 두 번째~네 번째 잔차 블록을 만듭니다\n",
        "    for blocks, filters in [(4, 128), (23, 256), (3, 512)]:\n",
        "        x = residual_stack(x, blocks, filters, first_stride=2)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_stack152(x):\n",
        "    # 첫 번째 잔차 스택의 첫 번째 잔차 블록만 스트라이드 1을 사용합니다\n",
        "    x = residual_stack(x, 3, 64, first_stride=1)\n",
        "    # 두 번째~네 번째 잔차 블록을 만듭니다\n",
        "    for blocks, filters in [(8, 128), (36, 256), (3, 512)]:\n",
        "        x = residual_stack(x, blocks, filters, first_stride=2)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ehjdGYXFi1ua"
      },
      "id": "ehjdGYXFi1ua",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0820d648-d92a-49fc-b2fc-bced3c2850f4",
      "metadata": {
        "id": "0820d648-d92a-49fc-b2fc-bced3c2850f4"
      },
      "source": [
        "## 강아지와 고양이 사진 분류하기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1xGkTT3uwYt4myj6eJJeYtdEFgTi2Sj8C\n",
        "!unzip cat-dog-images.zip"
      ],
      "metadata": {
        "id": "wQijOiwk3pqV",
        "outputId": "600d8f52-23fe-4039-aec1-2a8d902f060e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wQijOiwk3pqV",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xGkTT3uwYt4myj6eJJeYtdEFgTi2Sj8C\n",
            "To: /content/cat-dog-images.zip\n",
            "\r  0% 0.00/182k [00:00<?, ?B/s]\r100% 182k/182k [00:00<00:00, 61.4MB/s]\n",
            "Archive:  cat-dog-images.zip\n",
            "   creating: images/\n",
            "  inflating: images/dog.png          \n",
            "  inflating: images/cat.png          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bd3f2863-70af-4229-acba-5a434df6ae0b",
      "metadata": {
        "id": "bd3f2863-70af-4229-acba-5a434df6ae0b"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras.applications import resnet\n",
        "\n",
        "dog_png = Image.open('images/dog.png')\n",
        "resnet_prep_dog = resnet.preprocess_input(np.array(dog_png))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "61e066a2-f53d-49e8-803a-6c66ccf7c5bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61e066a2-f53d-49e8-803a-6c66ccf7c5bb",
        "outputId": "80428cb5-516f-4c86-8bda-dc30e3a37d5d",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n02099712', 'Labrador_retriever', np.float32(0.38535273)),\n",
              "  ('n02099601', 'golden_retriever', np.float32(0.089699574)),\n",
              "  ('n02100735', 'English_setter', np.float32(0.04212418)),\n",
              "  ('n02106166', 'Border_collie', np.float32(0.03777442)),\n",
              "  ('n02101388', 'Brittany_spaniel', np.float32(0.030700428))]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "resnet50 = keras.applications.ResNet50()\n",
        "predictions = resnet50.predict(resnet_prep_dog[np.newaxis,:])\n",
        "\n",
        "resnet.decode_predictions(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fee6e485-b606-42aa-a514-00831b88154f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fee6e485-b606-42aa-a514-00831b88154f",
        "outputId": "18394fa0-ddb6-4460-a223-280a3120c53e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n02123045', 'tabby', np.float32(0.8686101)),\n",
              "  ('n02124075', 'Egyptian_cat', np.float32(0.050774965)),\n",
              "  ('n02123159', 'tiger_cat', np.float32(0.042567052)),\n",
              "  ('n07930864', 'cup', np.float32(0.0027631458)),\n",
              "  ('n03443371', 'goblet', np.float32(0.0020991666))]]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "cat_png = Image.open('images/cat.png')\n",
        "resnet_prep_cat = resnet.preprocess_input(np.array(cat_png))\n",
        "predictions = resnet50.predict(resnet_prep_cat[np.newaxis,:])\n",
        "\n",
        "resnet.decode_predictions(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62c2e2cf-eef5-4220-b81b-6eda142775e3",
      "metadata": {
        "id": "62c2e2cf-eef5-4220-b81b-6eda142775e3"
      },
      "source": [
        "## 미니 프로젝트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fa3a3149-c952-4fe1-8c06-c1a857b65083",
      "metadata": {
        "id": "fa3a3149-c952-4fe1-8c06-c1a857b65083"
      },
      "outputs": [],
      "source": [
        "from keras.utils import load_img\n",
        "from keras.applications import inception_v3\n",
        "\n",
        "dog_png = load_img(\"images/dog.png\", target_size=(299, 299))\n",
        "incep_prep_dog = inception_v3.preprocess_input(np.array(dog_png))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "474394b5-774d-4729-8ff6-15fdb5924534",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "474394b5-774d-4729-8ff6-15fdb5924534",
        "outputId": "6d1de488-50a1-4bef-a9e1-bdd180c9261b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m96112376/96112376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n02104029', 'kuvasz', np.float32(0.13835053)),\n",
              "  ('n02099712', 'Labrador_retriever', np.float32(0.07777295)),\n",
              "  ('n02106166', 'Border_collie', np.float32(0.07198329)),\n",
              "  ('n02111500', 'Great_Pyrenees', np.float32(0.06614903)),\n",
              "  ('n02099601', 'golden_retriever', np.float32(0.02838334))]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "inception = keras.applications.InceptionV3()\n",
        "predictions = inception.predict(incep_prep_dog[np.newaxis,:])\n",
        "inception_v3.decode_predictions(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "525bdded-89b8-42c3-bdd2-91093fe1630f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "525bdded-89b8-42c3-bdd2-91093fe1630f",
        "outputId": "c3fa54a3-84ed-4a8c-8fe6-cf6a1db90f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n02124075', 'Egyptian_cat', np.float32(0.68673676)),\n",
              "  ('n02123159', 'tiger_cat', np.float32(0.13263007)),\n",
              "  ('n02123045', 'tabby', np.float32(0.04215029)),\n",
              "  ('n04040759', 'radiator', np.float32(0.0016103369)),\n",
              "  ('n02971356', 'carton', np.float32(0.0011297755))]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "cat_png = load_img(\"images/cat.png\", target_size=(299, 299))\n",
        "incep_prep_cat = inception_v3.preprocess_input(np.array(cat_png))\n",
        "predictions = inception.predict(incep_prep_cat[np.newaxis,:])\n",
        "inception_v3.decode_predictions(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e417d3e1-75fa-4eb9-bae5-cf14ffc10332",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e417d3e1-75fa-4eb9-bae5-cf14ffc10332",
        "outputId": "91133326-1839-47c7-efcb-ed600a155bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m225209952/225209952\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n02099712', 'Labrador_retriever', np.float32(0.6563314)),\n",
              "  ('n02104029', 'kuvasz', np.float32(0.13956322)),\n",
              "  ('n02099601', 'golden_retriever', np.float32(0.05594526)),\n",
              "  ('n02111500', 'Great_Pyrenees', np.float32(0.048894893)),\n",
              "  ('n02100735', 'English_setter', np.float32(0.0021178788))]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from keras.applications import inception_resnet_v2 as incep_res_v2\n",
        "\n",
        "incep_res_prep_dog = incep_res_v2.preprocess_input(np.array(dog_png))\n",
        "inception_resnet = keras.applications.InceptionResNetV2()\n",
        "predictions = inception_resnet.predict(incep_res_prep_dog[np.newaxis,:])\n",
        "incep_res_v2.decode_predictions(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6e8cfcca-f88d-4fc4-8e25-1eb0d0c220f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e8cfcca-f88d-4fc4-8e25-1eb0d0c220f2",
        "outputId": "1efc8d08-e6d6-40b2-a531-4dee5a59f721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n02123045', 'tabby', np.float32(0.4249481)),\n",
              "  ('n02124075', 'Egyptian_cat', np.float32(0.25831026)),\n",
              "  ('n02123159', 'tiger_cat', np.float32(0.1279524)),\n",
              "  ('n02127052', 'lynx', np.float32(0.003448608)),\n",
              "  ('n04525038', 'velvet', np.float32(0.0024461092))]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "incep_res_prep_cat = incep_res_v2.preprocess_input(np.array(cat_png))\n",
        "predictions = inception_resnet.predict(incep_res_prep_cat[np.newaxis,:])\n",
        "incep_res_v2.decode_predictions(predictions)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "common-cpu.m102",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m102"
    },
    "kernelspec": {
      "display_name": "Python 3.10 on Backend.AI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}