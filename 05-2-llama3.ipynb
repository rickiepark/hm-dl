{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cb145d9f-dc9d-4804-870f-b4866db0244e",
      "metadata": {
        "id": "cb145d9f-dc9d-4804-870f-b4866db0244e"
      },
      "source": [
        "# 05-2 Llama 모델로 텍스트 생성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30f3b4d4-5717-4b1c-a8a9-c4c98056667c",
      "metadata": {
        "id": "30f3b4d4-5717-4b1c-a8a9-c4c98056667c"
      },
      "source": [
        "<table align=\"left\"><tr><td>\n",
        "<a href=\"https://colab.research.google.com/github/rickiepark/hm-dl/blob/main/05-2-llama3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"코랩에서 실행하기\"/></a>\n",
        "</td></tr></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yCXoZXSjKXXb",
      "metadata": {
        "id": "yCXoZXSjKXXb"
      },
      "source": [
        "코랩에서 이 노트북을 실행하려면 A100이나 High-RAM CPU 런타임을 사용해야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ad61b84-6342-472f-aa6e-859f5c7369ad",
      "metadata": {
        "id": "3ad61b84-6342-472f-aa6e-859f5c7369ad",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Llama-3 모델로 텍스트 생성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 허깅페이스에 Llama-3 사용 허가 요청하기"
      ],
      "metadata": {
        "id": "Rel8xlv6EfKS"
      },
      "id": "Rel8xlv6EfKS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b7c2610-40d1-4c62-bdaf-af29815b035a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "dcd5e9c749f44110ac3094c20c1c3126",
            "33658a981f1844f086083be4381a4aaf",
            "87ca4db7b1d34ebc8bab843b7c5e4d08",
            "276e6cb76d124c70a643e9c4cea6a861",
            "6989e618d0104728a06523c79761511b",
            "febd90ee322a43d58b9fedbc046edbbf",
            "f532e12c894541a98e471064be8729a0",
            "06802a07b7e947b382a615d8013e68a8",
            "b5f08a7d341f42ac955a49bc565c4c2a",
            "66b9fe79b48e4eb2b405dc17ecb30d8d",
            "04ff01589c7f43fe81ff3ff4525de894",
            "9420d88650e54adba371bccdcc52e5ba",
            "e4e0486dfc1c43e0bfb63a9c35e5e83d",
            "d55f9f001edc4337bc767952c2bb9e3f",
            "47464ab48d324a86907e645c348333f1",
            "27688745a7a640e18c06e2a9bda2117b",
            "7ce63725cd324c60b867800b22f17129",
            "8fb37f79ff6d4dfb90e610f10050f16e",
            "1f8bbc088eed44538693200be50f8258",
            "19ded5562ee34c0abda4cab5704be51a"
          ]
        },
        "gather": {
          "logged": 1716196630861
        },
        "id": "4b7c2610-40d1-4c62-bdaf-af29815b035a",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "outputId": "d79f391b-a996-42a8-e2ff-7a65b9f47cad"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dcd5e9c749f44110ac3094c20c1c3126"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06cdcf9f-2e7c-4325-a290-fc46e4ead886",
      "metadata": {
        "id": "06cdcf9f-2e7c-4325-a290-fc46e4ead886",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Llama-3 구조 살펴 보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ovHyEYo0tYy",
      "metadata": {
        "id": "9ovHyEYo0tYy"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, set_seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81412a36-6e68-4a5a-90e1-d13b7d58da73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419,
          "referenced_widgets": [
            "57137a34c9e344be84a277cb8554e1d0",
            "846d34f261724395a3443cfbb4944f9d",
            "436f082c5d0d4283815c41d262cea4bb",
            "945694e0d1cc4435845b4049823c0376",
            "b320300da8bf48fe9d5891f9618dbc1e",
            "bf90727f4ad444d696db69cf04bcf271",
            "b2a811db15ac4b02bf743ba9ac4f7778",
            "e6ebda5cb6304a2eac4607a1b4264037",
            "0c846ab1782c4732aa6577db36fcd504",
            "c5fc3e256c314add8801834412b7f9fd",
            "3ddc199f6c544156a9be93fd4975ae33",
            "f97b3df6c9054ed98c9e32ecc013d67a",
            "078b10d5e0c94f468ed373dd3bb86b88",
            "49cd85c7caad40e0bd30ee33cad26bf4",
            "70fe29b0e63f443699d501f3f7d0f5ba",
            "9faeaf09384d42e89aec82d74bd02d4a",
            "e7468994eb6d4458855f15a22676714a",
            "2fee42cc47b54698a82d1ec2a22add36",
            "d0f7c0424b0d494a8e4b45a9f937be92",
            "7521aff83141450fb7315d6e917277e4",
            "90a406f9dc92452790c5882be508df58",
            "3c0b25c5e9f64ebfb415662da36bbc37",
            "ac9a6bf16227439d87178c7a6e806787",
            "929e9043acee405cbccc317f51c05d47",
            "b1d3c1d8aaf7460d98719a8b7671791c",
            "4b20cb16fd0c40e989cb37fc8636b487",
            "cab17ca64966438da38b784980299340",
            "e8183672b1894d1ea7ef4f136ff64430",
            "58d91c6ddc954ff3b2d8b2c79f0cf5dd",
            "e9b10e892cb748cba589e4be7eb862d3",
            "ebfe981a9c994942b16503a2902309fa",
            "d05f45f8daeb45b1aa25200c4c33f704",
            "cb5df52ed65948f7b95f5851cc392881",
            "2d2b3d5b40e14b32af71ba76eaa2a2b2",
            "673bd9ea5ed24bfe897d7d6629918fb0",
            "316e8b5fa3374eb495d63939ecf721c1",
            "a771fcb11e3041c3946c3366406128b4",
            "521a7027fde842f2807be77238c7c7d8",
            "7a939943128a4052ba4eb0e4c26d7795",
            "555a5c109f5f4929b104e005285b91a5",
            "c958dd1774ad4aba899491e816a0bae9",
            "5e9ae4f5ab424749b235624c105c73e8",
            "e4fae94397d54ea9859cf90634c5dc7a",
            "ac3e93962ad14339b107ab912de4a8e4",
            "d4ec4b956896402c8726c7d6fffdb945",
            "0c7dcc6aa8144d568761749dd6bc714f",
            "fa9fea77c1a04653a771853623062e89",
            "a5441ad3d80e473287c0250310b37d49",
            "24676e5ff60a4dfea0ff57caba957edb",
            "53681ffd3c834a20affb94374322a7dc",
            "603c308e325840cd86b36ab2921f770d",
            "416d0c40e5f34e85bd043e1ad141f46a",
            "01d38ac49acf457bb0f1d6d5c0e21ae1",
            "825a34b4b88b418899ae00da0f7a4351",
            "e18cd5036e6b42a2bbf8d87254769406",
            "ff21d021aa494ccf9e1ef89e4dbb6c9a",
            "1bc36ff785f9461cae41d3294d439583",
            "42712c34b1a24294ba7ffd1d1474ffa2",
            "cc4c314c54b34f069827a1824fe204af",
            "6581c07b7f3842c08ae567766e99a381",
            "71a3201faae34b2485db01f1fec93a93",
            "58dfe883bfed448f846133d63c39bbce",
            "c0c5363db7514e39b11a1d1e0df5c3a9",
            "834bd5df192d407181b348e0d7f8e274",
            "223c009978a8474e878b7b5402f1f3bb",
            "3d774d300ea64b5bb2b2eae614047dde",
            "cbde835046d9417e8cb326b8e9bcf689",
            "e7f601a2856947218bdc5c761e3f8743",
            "9e10bd015386469e829e9f5316afb438",
            "2901b189178a4db49521991010d1cc99",
            "c56bc96e9291439684c92d6488eb0ea4",
            "b27ebb926b66476d814fee9e7dbfe0df",
            "9da50312f3cf4b328be3833ce660200c",
            "28ad2fcc7e154fc9b1670e348e9fd616",
            "f8e36d5e4b4949c28bc84e912aa47f96",
            "7b6b55ac074e47068e473ff154d3d7f9",
            "1196f951e0c044cb81230b3703057930",
            "f7a735eb57dd422493d351e69cc3bba0",
            "8ab4856d960a4caebd0d9ecf3807be5c",
            "017c212e1d2d495baf174c1a006de272",
            "5424c62ece7541ffa6a7672396c28c64",
            "1bfd5992384f494881be1dc2f9b29a14",
            "2f8ee6c674254fcb86bbd9ead863945e",
            "0238291736d5410194aa6c3797160c1c",
            "636d3fe53eff4e1aa45f76dc4ea76aea",
            "d1cae8caf36a4c5fa5b66a209079f1ad",
            "a419446412f74f238617f1fd4dbe5ec5",
            "23861277e19a469c9b13e0841f91d1ec",
            "41a60868b9fa4c63a433118dd6dceaaa",
            "6b04e6dc7e1f44039c1b9bfc58f5f3a5",
            "8d91a6f5fcd1400ea9e0ad763eda73fa",
            "43d1ca3637554b7089efbbe9a7f7d15f",
            "ebc18aee387242349f7517a8170c13b9",
            "26910613a29e41d480620fc54015fdd2",
            "489dfcb44b7a4143b833ddee61b288f3",
            "d461103fcc824fa5995df06e28e3979c",
            "090e4f5f529146029235af69029f7e41",
            "e220933f3f6d4b2e8454a2f1a84f3adc",
            "ca46a1dee2d64122a92d3238a9f4830b",
            "e6d0f72cdc2342cd94b6f3de6bb8d911",
            "360eb5fabafc4638836fa47552c2f782",
            "355f713735f441768a0299840f61d2ee",
            "9df842afd12244879c9bc321ada16b54",
            "039c69efcf4547899d35027297cb6a25",
            "c608c8dcd260437395c3ba9cf23337b9",
            "788cee096c6346c7819da7dae2a29a04",
            "61f34da2d43949ff837faaa195b32923",
            "1da781a72d7f4048858e9df04781aabf",
            "6536c4cf36d840859788867b7e36a018",
            "96d75056265e41daaa55ac4a6d049927",
            "707ca85fc33f4d3a8a2d3ad6c6a99e76",
            "2802282dd9cd471c9ddb47d5be0c2b8f",
            "05a0abdc93954f1986e293be17f74366",
            "9e9264b96c204b9d97fe1185320f408f",
            "a29d3f66926142e2b01cdc1d6dfc8b9b",
            "719182bf001d499b961a9cc069481bf4",
            "962b9ae0be584fd9bb874667cb25290c",
            "c4dee4b01e2c422ebea34b32f8db95e3",
            "12c70a2134994c6fbfd89116378256a6",
            "cf1571d14da94ec69f8b0606269d7471",
            "5f242f59e45d40c29082e5c20c3b829c",
            "9d5d73cc9cb140c18f01d9d318d963d5",
            "7a11d5e9475a4a0baa68c686af33d0b0",
            "2cfea02699604659a526b4c407abb532",
            "3a57fc5bda4841f098cbeb7da520e4cd",
            "01fd623ff52340b4ae923f6521179437",
            "42a8612a1f4942b99e757076e799f45d",
            "e53e11f316984670afdd178dfd8af04f",
            "43fd991b45114842ba37a5a4dd1e643c",
            "a9000e2f2f5d4cc780497cd70b1c7531",
            "89d8658438f642fdb3eecf38db9e7316",
            "3575ebd160844ffd8945613a0b5bb6ff"
          ]
        },
        "gather": {
          "logged": 1716347333870
        },
        "id": "81412a36-6e68-4a5a-90e1-d13b7d58da73",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "outputId": "f0bcb3ee-cbf1-4b49-96e5-b49683484a3a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57137a34c9e344be84a277cb8554e1d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f97b3df6c9054ed98c9e32ecc013d67a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac9a6bf16227439d87178c7a6e806787",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d2b3d5b40e14b32af71ba76eaa2a2b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4ec4b956896402c8726c7d6fffdb945",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff21d021aa494ccf9e1ef89e4dbb6c9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbde835046d9417e8cb326b8e9bcf689"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7a735eb57dd422493d351e69cc3bba0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41a60868b9fa4c63a433118dd6dceaaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6d0f72cdc2342cd94b6f3de6bb8d911"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "707ca85fc33f4d3a8a2d3ad6c6a99e76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d5d73cc9cb140c18f01d9d318d963d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "llama3_pipe = pipeline(\"text-generation\", model=\"meta-llama/Meta-Llama-3-8B\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05f6ef86-9b87-4544-99b1-2eb350636107",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1716258582942
        },
        "id": "05f6ef86-9b87-4544-99b1-2eb350636107",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "outputId": "af1da537-0ad2-485f-9303-8265583be950"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(128256, 4096)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaAttention(\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "llama3_pipe.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3917b0b-6d95-42ee-9a80-058cdb7faeae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": false,
        "id": "a3917b0b-6d95-42ee-9a80-058cdb7faeae",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "outputId": "e31af23e-3cdf-4bc8-d256-aea76710317b",
        "run_control": {
          "frozen": true
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d3a6d64-fb16-4b8d-9046-674e8294d8d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1716347427749
        },
        "id": "0d3a6d64-fb16-4b8d-9046-674e8294d8d2",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "outputId": "508ecb51-5079-4987-9a51-5287fc64d906"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "======================================================================\n",
              "Layer (type:depth-idx)                        Param #\n",
              "======================================================================\n",
              "LlamaForCausalLM                              --\n",
              "├─LlamaModel: 1-1                             --\n",
              "│    └─Embedding: 2-1                         525,336,576\n",
              "│    └─ModuleList: 2-2                        --\n",
              "│    │    └─LlamaDecoderLayer: 3-1            218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-2            218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-3            218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-4            218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-5            218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-6            218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-7            218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-8            218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-9            218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-10           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-11           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-12           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-13           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-14           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-15           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-16           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-17           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-18           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-19           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-20           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-21           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-22           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-23           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-24           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-25           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-26           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-27           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-28           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-29           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-30           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-31           218,112,000\n",
              "│    │    └─LlamaDecoderLayer: 3-32           218,112,000\n",
              "│    └─LlamaRMSNorm: 2-3                      4,096\n",
              "│    └─LlamaRotaryEmbedding: 2-4              --\n",
              "├─Linear: 1-2                                 525,336,576\n",
              "======================================================================\n",
              "Total params: 8,030,261,248\n",
              "Trainable params: 8,030,261,248\n",
              "Non-trainable params: 0\n",
              "======================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(llama3_pipe.model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65bed663-07c5-49bd-b384-cca3d987d56f",
      "metadata": {
        "id": "65bed663-07c5-49bd-b384-cca3d987d56f",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Llama-3와 미세 튜닝 모델 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a138bfc-b2c0-411c-b34c-b416f9f43700",
      "metadata": {
        "gather": {
          "logged": 1716259170678
        },
        "id": "1a138bfc-b2c0-411c-b34c-b416f9f43700",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "llama3_pipe.model.generation_config.pad_token_id = llama3_pipe.tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15314da1-5a94-4670-a58b-3271de8ea214",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1716288916836
        },
        "id": "15314da1-5a94-4670-a58b-3271de8ea214",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "outputId": "4e49d913-ec82-418a-e7aa-4baaaa975df3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'stay hungry, stay foolish, stay humble, stay motivated, stay curious, stay creative, stay'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "set_seed(42)\n",
        "llama3_pipe('stay hungry, stay', max_length=20, truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a849b44-d25a-4816-a9d9-7399cd495069",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1716262137986
        },
        "id": "9a849b44-d25a-4816-a9d9-7399cd495069",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "outputId": "f1c34e41-178b-4876-f5d1-1cb51d559d9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GenerationConfig {\n",
              "  \"bos_token_id\": 128000,\n",
              "  \"do_sample\": true,\n",
              "  \"eos_token_id\": 128001,\n",
              "  \"max_length\": 4096,\n",
              "  \"pad_token_id\": 128001,\n",
              "  \"temperature\": 0.6,\n",
              "  \"top_p\": 0.9\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "llama3_pipe.model.generation_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be063b41-ccd7-4293-9a44-9dca457febf0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "gather": {
          "logged": 1716293065766
        },
        "id": "be063b41-ccd7-4293-9a44-9dca457febf0",
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "outputId": "9325ae35-c8bf-4db8-810e-88d6bc8f38b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': '봄이 오면, 봄에 맞는 음식이 나오는 것 같은데'}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "set_seed(42)\n",
        "llama3_pipe('봄이 오면', max_length=20, truncation=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernel_info": {
      "name": "py310_tf216_keras3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}